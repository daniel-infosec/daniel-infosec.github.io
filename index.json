[{
    "title": "Real Time vs Scheduled Query Detections - A Guide For Detection Engineers",
    "date": "",
    "description": "Many SIEM tools nowadays offer both the opportunity for you to write rules on streaming data or run scheduled queries on a periodic basis. But when should you use which and why?",
    "body": "Most modern SIEMs offer 2 primary methods for running their queries: real time rules and scheduled queries. Each option offers a variety of pros and cons that you should consider as you develop your detection. Before we dive into that, let\u0026rsquo;s clarify what we mean by each.\nDefinitions A real time rule, often called a streaming rule, runs on a stream of data. Essentially, as the data enters the SIEM, each data point will get processed against the rules that correspond with that kind of data. Let\u0026rsquo;s take a look at some examples.\nOKTA_SUPPORT_ACCESS_EVENTS = [ \u0026quot;user.session.impersonation.grant\u0026quot;, \u0026quot;user.session.impersonation.initiate\u0026quot;, ] def rule(event): return event.get(\u0026quot;eventType\u0026quot;) in OKTA_SUPPORT_ACCESS_EVENTS def title(event): return f\u0026quot;Okta Support Access Granted by {event.udm('actor_user')}\u0026quot; def alert_context(event): context = { \u0026quot;user\u0026quot;: event.udm(\u0026quot;actor_user\u0026quot;), \u0026quot;ip\u0026quot;: event.udm(\u0026quot;source_ip\u0026quot;), \u0026quot;event\u0026quot;: event.get(\u0026quot;eventType\u0026quot;), } return context The above rule is from Panther and can be found at okta account support access.\nThe rule is configured to run on Okta logs. For every event, it determines if the event type was in a list of defined Okta support access events. This rule runs as the Okta logs are ingested into Panther and is near-real time: as soon as the logs are shipped to Panther, the rule runs.\nNow, let\u0026rsquo;s take a look at a scheduled query.\nAnalysisType: scheduled_query QueryName: Okta Investigate MFA and Password resets Enabled: true Description: \u0026gt; Investigate Password and MFA resets for the last 1 hour SnowflakeQuery: \u0026gt; SELECT p_event_time, actor:alternateId as actor_user, target[0]:alternateId as target_user, eventType,client:ipAddress as ip_address FROM panther_logs.public.okta_systemlog WHERE eventType IN ('user.mfa.factor.reset_all', 'user.mfa.factor.deactivate', 'user.mfa.factor.suspend', 'user.account.reset_password', 'user.account.update_password', 'user.mfa.factor.update') and p_occurs_since('1 hour') ORDER by p_event_time DESC Schedule: RateMinutes: 60 TimeoutMinutes: 1 The above query can be found here: okta mfa reset (though it was modified for this blog post)\nThis query operates on data that has already been ingested into the SIEM. Every hour, it runs a SQL query over the Okta system logs and looks for events related to MFA. If any match, it will generate an alert.\nTypes of Cost I believe that nearly any rule you write as a streaming rule you can also write as a scheduled query and vice versa. So why would one choose one over the other? It comes down to cost in more ways than one. First, let\u0026rsquo;s identify the types of cost.\n Real Time Analytics - some SIEMs charge for the cost of running real time analytics. Batch Processing - some SIEMs will charge for running analytics and may have different charges for real time vs scheduled rules. Enrichment - nearly every alert nowadays requires enrichment. With a real time rule, this often can be done with lookup tables or calling an external API. With a scheduled query, one can use joins. Development - time is money friends! If a rule takes longer to develop and test, that\u0026rsquo;s a cost that needs to be accounted for. Error Potential - failures can be disastrous for a SOC as they can cause false negatives leading to an extended breach. What can cause errors for these rules? For a streaming rule relying on an API for enrichment, you can run into rate limiting or just general API failures if the API goes down. For a scheduled query where you\u0026rsquo;re relying on joins, you can run into data ingestion delay sync issues. Let\u0026rsquo;s dive into this more.  Data Ingestion Failures Let\u0026rsquo;s refer to our above scheduled query. In this scenario, we\u0026rsquo;re ingesting Cloudtrail, Okta, and Jamf into our data lake. Let\u0026rsquo;s imagine that our Jamf ingestion gets delayed for whatever reason. And during this delay, a user starts working from a coffee shop with a new public IP address. We could very easily run into a false positive as the user\u0026rsquo;s new laptop IP would not be in our data lake yet. We can also imagine similar false negatives where an inner join can fail due to data ingestion. How do we solve this issue? We have a couple of options.\n Staggered data lookbacks. Instead of looking back from -1 hour to present, we could look back -2 hours to -1 hours. This gives us a buffer window for data to hit our data lake. However, it automatically increases our time to detect by 1 hour. Overlapping lookbacks. Now let\u0026rsquo;s imagine we lookback -2 hour to present but we run every 1 hour. This keeps our time to detect at a more reasonable threshold, but we\u0026rsquo;re greatly increasing the volume of data we\u0026rsquo;re examining. We\u0026rsquo;ll also have to be cautious of how we plan for alert deduplication.  Example Costs Let\u0026rsquo;s take a look at some examples of common detections and see where their costs are.\n Streaming rule on firewall logs looking for IoC IPs  Let\u0026rsquo;s look at some example code.\nfrom ioc_library import lookup_ioc def rule(event): return lookup_ioc(event.udm(\u0026quot;source_ip\u0026quot;)) or lookup_ioc(event.udm(\u0026quot;dest_ip\u0026quot;)) def title(event): if lookup_ioc(event.udm(\u0026quot;source_ip\u0026quot;)): return f\u0026quot;Source IP ({event.udm('source_ip')}) matched a known IoC\u0026quot; else: return f\u0026quot;Dest IP ({event.udm('dest_ip')}) matched a known IoC\u0026quot; In this sample code, we have a library that allows us to pass in an IP and query an API to see if the IP matches a known IoC. What potential costs could we have?\nWe\u0026rsquo;re going to have real time analytic and enrichment costs. Especially concerning is the fact that we\u0026rsquo;re calling the lookup_ioc function up to 3 times. Depending on the volume of our firewall traffic, it\u0026rsquo;s very likely we could run into a rate limit on the API.\nScheduled query matching AWS logins with Okta usernames with Jamf IPs  AnalysisType: scheduled_query QueryName: Okta AWS Console Logins from Non-Laptops Enabled: true Description: \u0026gt; Investigate AWS console logins from Non-Laptops SnowflakeQuery: \u0026gt; SELECT * FROM panther_logs.public.cloudtrail ct INNER JOIN panther_logs.public.okta_users okta on okta:email like CONCAT('%', lower(ct:userIdentity.userName), '%') LEFT OUTER JOIN panther_logs.public.jamf_inventory jamf on jamf:externalIP = ct:sourceIPAddress WHERE ct:eventName = 'ConsoleLogin' and p_occurs_since('1 hour') and jamf:externalIP is NULL ORDER by p_event_time DESC Schedule: RateMinutes: 60 TimeoutMinutes: 1 In the above login, we\u0026rsquo;re joining our Cloudtrail data with Okta, and then joining that again on Jamf data to see where users are logging in from devices that aren\u0026rsquo;t their laptops. How would we write this if it was a streaming rule? Similarly to the first example, we\u0026rsquo;d have to have an API where we could pass an IP and see if that IP is associated with one of our devices in Jamf.\nWhat are the costs here?\nWe\u0026rsquo;re going to have processing costs in our SIEM - if we have a lot of Cloudtrail logs, we could be searching a lot of data. Additionally, while not super relevant in this example, depending on the join we could face costs/performance concerns.\nDeciding on a Style Now that we\u0026rsquo;re familiar with some of the costs, what questions should we ask ourselves when designing a rule?\nFactors that favor real time rules How quickly do I need to be alerted?\nA streaming rule will notify your SOC/IR team in near-real time. If the rule doesn\u0026rsquo;t require an immediate response, one could use a scheduled query.\nHow much data do I need to look at?\nLet\u0026rsquo;s envision we\u0026rsquo;re using a scheduled query that\u0026rsquo;s using data source A and B, and we\u0026rsquo;re joining the past hour of A on all of B. If B is a very voluminous data source, we could be looking at a very slow query. In this case, it may be better to run a streaming rule on A and then query B as necessary in the next step of the pipeline.\nHow many rules do I have running on this data set and how large is the data set?\nLet\u0026rsquo;s say we\u0026rsquo;re writing rules on VPC flow log data which has a LOT of data. Let\u0026rsquo;s say we want to write 5 different rules to look for IoCs, unexpected ports, etc. (ones that are very simple). If we were to write 5 different scheduled queries, we would be looking at the same (large amount of) data multiple times. This can get expensive. We could write 1 scheduled query but it would be complicated and hard to parse. So in this case, writing streaming rules would make more sense and we could rely on downstream enrichments.\nFactors that favor scheduled queries Do I need enrichment to generate an alert?\nIn our first example, we needed to enrich our data in order to generate an alert. This means we\u0026rsquo;ll need to call an API on every data record. On the other hand, if we only need to call the API after we\u0026rsquo;ve decided to generate an alert, we\u0026rsquo;ll significantly reduce how often we\u0026rsquo;ll need to call the API and avoid potential rate limit concerns.\nHow many data points do I need to make a conclusion?\nIn our second example, we needed Cloudtrail, Okta, and Jamf in order to make a determination if the login was malicious. This would be difficult to do with a real time rule as it would likely require the development of specific infrastructure to support these lookups.\nHow well does my infrastructure handle failure?\nLet\u0026rsquo;s say you hit a rate limit and your API lookup fails. What happens? Does your infrastructure rerun the rule at a later date? Or does your infrastructure ignore the event and not process it? If you suspect you may hit a rate limit with your rule and your infrastructure fails silently, you should consider re-designing the rule or running it as a scheduled query.\nDo I need to consider system state?\nLet\u0026rsquo;s imagine a scenario where we have an endpoint security tool, and we want to alert if it\u0026rsquo;s uninstalled. However, our IT team has a script that is triggering false positives because it temporarily disables the agent when it applies updates. So we want to know what state the system was in when the disable command was run. You could potentially set up some sort of state analysis pipeline, but it can get prohibitively expensive. It\u0026rsquo;s much simpler to use joins or something like match_recognize.\nOther Factors What\u0026rsquo;s my team familiar with?\nIf your team is more familiar with real time rules, you should defer to that. It\u0026rsquo;s likely your existing infrastructure and tooling better supports development and testing of those rules. That doesn\u0026rsquo;t mean you should ignore the alternative all together, though!\nWhat infrastructure and supporting automation and tooling have we already built?\nAre you architected around ingesting all your data into your security data lake? Or do you have a robust series of APIs to query 3rd party endpoints? This could drive your decision one way or the other; though with Snowflake\u0026rsquo;s UDF support, you could call these APIs from your scheduled queries if you wish.\nConclusion There\u0026rsquo;s some great blog posts on detectio engineering out there, but I often see them focusing too much on theory or on the nitty gritty of some technology. My hope is that this article will be useful to practioners especially those who are charged with architecting their detection systems.\nNow that you’ve got this information and are equipped with these questions, you’re prepared to make better decisions when it comes to designing your rules. Are there other things you consider during your design process? Please let me know!\n",
    "ref": "/blog/streamingvsscheduling/"
  },{
    "title": "A Shmoo's Guide to DC",
    "date": "",
    "description": "While the hotel bar and the restaurants right around it present an easy opportunity to fill up, I feel like I owe it to provide some recommendations of where I think some of the best places to hang out around the hotel are.",
    "body": "Some of these recommendtions work best for Shmoocon in March vs Shmoocon in the cold of January.\nOrienting Yourself\nBelow is a map of the neighborhoods. The gold star is the Hilton hotel. When you hear someone reference a neighborhood, hopefully this helps. The most common ones you\u0026rsquo;ll probably hear are Adams Morgan (Admo), Dupont Circle (Dupont), U St, The Mall, and Capitol Hill.\nGetting Around\nMetro\n Dupont station is going to be closest and that\u0026rsquo;ll get you to the red line. You probably won\u0026rsquo;t need to take the Metro unless you\u0026rsquo;re heading to Amtrak or heading out to Virginia or DCA (Airport).   Buses\n Metrobus. This is the main bus system for DC. It\u0026rsquo;s heavily commuter focused. https://www.wmata.com/schedules/maps/. Circulator  https://www.dccirculator.com/ride/rider-tools/interactive-map/ Your best bet to get to georgetown without walking. It comes frequently and it\u0026rsquo;s only $1.    Hopping Areas\n Admo Dupont 14th St NW (between Logan Circle and U St)  Barcelona  Wine bar   Player’s Club  Arcade bar   Chicken \u0026amp; Whiskey Colada Shop  Cuban \u0026amp; Cocktails     U St  Head towards the loud music near 801 Florida Ave NW, Washington, DC 20001 You can’t really mess up just bar hoping hear Lots of rooftop areas   Georgetown  I don’t go out hear a lot, but there’s some decent bars. You’re going to get a different group here - mix of college students and older DC residents   The Navy Yard  It\u0026rsquo;s a bit of a hike, but worth it imo. Good restaurants, bars, and you\u0026rsquo;re right on the water. Good for a nice Spring day.    Drinking\nNearby\n McClellans Reterat Board Room  Board games!   Dan’s Cafe  Notorious for their pour your own drinks   Jack Rose  Whiskey    Cocktails\n Barmini - expensive, reservation required, but so good Thai Chef Street Food - surprisingly good cocktails Residents dC - https://www.residentsdc.com/menus/#cocktail-menu thanks @jamieantisocial Anyone have other recommendations for ones near the hotel?  Whiskey\n Jack Rose  Speakeasies\n Chicken \u0026amp; Whiskey (in the back behind the metal door) Left Door (Need a reservation I believe) The Gibson (Need a reservation I believe)  Partying\n U st (search around TAKODA)  Eating\nNearby\n Lucky Buns (Long wait) Thai Chef Street Food  My favorite Thai in the city Great cocktails    Pizza\n Andys  Thai\n Thai Chef Street Food (You maybe can tell I like this place)  Steak\n Sourcing recommendations  Ethiopian\n DC is famous for their ethiopian, but I actually haven\u0026rsquo;t had it recently, so I\u0026rsquo;m sourcing recommendations  Late bites (nearby)\n Dc pizza \u0026amp; kabob Duccinis El Tamarindo McDonalds (Admo) Andys (Admo)  Snacks/Sweets\n Foxtrot (like an upscale 7-11) Insomnia cookies - late night cookies Jenis - my favorite ice cream place Un je ne sais Quoi… - really good french bakery  Breakfast\n Bethesda bagel Ted’s Bulletin - alcoholic milkshakes and the homemade poptarts are the stars  Just Plain Good\n Anju Iron Gate Jinya (ramen)  Chinese\n Great Wall Szechuan. It’s the best. I won\u0026rsquo;t be debating this :)  Other\n Dupont farmers market  Call your mother bagels - best bagels in DC Fresh fruit    Outdoors\n Meridian Hill Park. This is a really nice park nearby. When the weather is nice, there\u0026rsquo;s a lot of people hanging out, dogs, music, etc. National Mall. Of course. Do your best to skip the food trucks. They\u0026rsquo;re generally not worth it.  Restroom map: https://www.nps.gov/common/uploads/grid_builder/nationalmall4th/crop1_1/653C856A-C02B-92D6-BD93E5C8A469CDBC.jpg   Rock Creek Park. This park can take you pretty far. https://www.alltrails.com/explore/us/washington-dc/washington?b_tl_lat=38.925643460593164\u0026amp;b_tl_lng=-77.0563698317884\u0026amp;b_br_lat=38.91909424386935\u0026amp;b_br_lng=-77.04043356221366  ",
    "ref": "/blog/ashmoosguidetodc/"
  },{
    "title": "Azure Flow Log Analysis",
    "date": "",
    "description": "Azure flow logs don't have the same instance ID that AWS flow logs do. So how do you figure out which VM the logs came from?",
    "body": "Intro Disclaimer I currently work at Snowflake and use the product on a daily basis for log analysis and threat detection. At the time of this writing, that probably adds bias to my article.\nAt Snowflake, we\u0026rsquo;re a multi-cloud environment. As part of the threat detection team, it\u0026rsquo;s my job to ensure that we\u0026rsquo;re monitoring. One of my tasks was to monitor our Azure flow logs for unusual behavior. Information on Azure Network Security Group (NSG) flow logs can be found at this link. When I started exploring this data source, I was frustrated to learn that, unlike the AWS VPC flow logs, there was no field that ties the flow log to the instance ID, or in the case of Azure, the Virtual Machine. The recommended solution from Microsoft was to use the IP address. However, the architecture I was working in had thousands of worker nodes created and destroyed frequently meaning that we would often see duplicate IP addresses within a short period of time due to NATing. If I couldn\u0026rsquo;t automatically tie the IP to a VM, the logs would be useless as our IR team needed that information in order to conduct automated response in case of a malicious event.\nPlotting Fortunately, I had SQL to help. To conduct my analysis, I used Snowflake, which is where we (obviously) store our logs. However, any SQL tool should offer the same capabilities below. In order to conduct this analysis, I used a trick taught to me by one of the data scientists at Snowflake. First, for Azure logs, IPs aren\u0026rsquo;t associated with VMs. They\u0026rsquo;re associated with NICs and a NIC is associated with a VM. Now, a lot of organizations use various tools and scripts that collect information about current assets periodically. However, considering Snowflake creates and destroys VMs and NICs so rapidly, this isn\u0026rsquo;t sufficient. We also needed to look at the Azure operation logs in order to establish confidence that we were looking at every NIC. Let\u0026rsquo;s take a look at some code.\nselect parse_json(propertiesresponseBody) as response_body, response_body:etag::string as etag, response_body:name::string as nic_name, response_body:location::string as nic_locatin, response_body:properties as nic_properties, response_body:tags as tags, response_body:type::string as nic_type, value:properties.privateIPAddress::string as nic_ip from azure_operation_logs_v, lateral flatten(parse_json(properties:responseBody):properties.ipConfigurations) where operation_name = 'MICROSOFT.NETWORK/NETWORKINTERFACES/WRITE' You can review the documentation on the structure here: Network Interfaces - Create Or Update.\nThis gets us information on NICs from our operation logs. We also had have scripts running that collect information on existing NICs. This is useful for looking at longer running VMs.\nwith nic_collect_logs as ( select id::string as nic_id, etag::string as etag, nic_name::string as nic_name, nic_location::string as nic_location, nic_properties, tags, nic_type::string as nic_type, value:properties.privateIPAddress::string as nic_ip 'collect_script' as source min(recorded_at) as earliest, max(recorded_at) as latest from AZURE_COLLECT_NETWORK_INTERFACES_V, lateral flatten(properties:ipConfigurations) group by 1,2,3,4,5,6,7,8,9 ) select * from nic_collect_logs; This is slightly different. We wanted to remove duplicate NICs by using group by and also note the first time we saw the NIC and the most recent time we\u0026rsquo;ve seen the NIC. Let\u0026rsquo;s apply the same to the NICs collected by the operation logs.\nwith nic_create_op_logs_raw as ( select parse_json(propertiesresponseBody) as response_body, response_body:etag::string as etag, response_body:name::string as nic_name, response_body:location::string as nic_location, response_body:properties as nic_properties, response_body:tags as tags, response_body:type::string as nic_type, value:properties.privateIPAddress::string as nic_ip value:properties.entity::string as nic_id, 'operation_logs' as source from azure_operation_logs_v, lateral flatten(parse_json(properties:responseBody):properties.ipConfigurations) where operation_name = 'MICROSOFT.NETWORK/NETWORKINTERFACES/WRITE' ), nic_create_op_logs as ( select nic_id, etag, nic_name, nic_location, nic_properties, tags, nic_type, nic_ip, source min(event_time) as earliest, max(event_time) as latest from nic_create_op_logs from nic_create_op_logs group by 1,2,3,4,5,6,7,8,9 ) select * from nic_create_op_logs; So now we have NICs created by operational logs and NICs identified from our collection scripts. Let\u0026rsquo;s combine them together using union.\nwith all_nics as ( select * from nic_create_op_logs UNION select * from nic_collect_logs ) select * from all_nics; Now, the issue comes up where we want to know the window of time that a NIC had a particular IP address. We can do this using the lead and lag functions to get the start and end window times for a NIC\u0026rsquo;s association with an IP address. In this case, we can use true_earliest as the window start. To find the window_end, we\u0026rsquo;ll use lead\nselect *, true_earliest as window_start, lead(true_earliest) over ( partition by nic_ip order by true_earliest asc ) as window_end from all_nics ; The Code Putting all the code together we have\nwith nic_collect_logs as ( select id::string as nic_id, etag::string as etag, nic_name::string as nic_name, nic_location::string as nic_location, nic_properties, tags, nic_type::string as nic_type, value:properties.privateIPAddress::string as nic_ip 'collect_script' as source min(recorded_at) as earliest, max(recorded_at) as latest from AZURE_COLLECT_NETWORK_INTERFACES_V, lateral flatten(properties:ipConfigurations) group by 1,2,3,4,5,6,7,8,9 ), nic_create_op_logs_raw as ( select parse_json(propertiesresponseBody) as response_body, response_body:etag::string as etag, response_body:name::string as nic_name, response_body:location::string as nic_location, response_body:properties as nic_properties, response_body:tags as tags, response_body:type::string as nic_type, value:properties.privateIPAddress::string as nic_ip value:properties.entity::string as nic_id, 'operation_logs' as source from azure_operation_logs_v, lateral flatten(parse_json(properties:responseBody):properties.ipConfigurations) where operation_name = 'MICROSOFT.NETWORK/NETWORKINTERFACES/WRITE' ), nic_create_op_logs as ( select nic_id, etag, nic_name, nic_location, nic_properties, tags, nic_type, nic_ip, source min(event_time) as earliest, max(event_time) as latest from nic_create_op_logs from nic_create_op_logs group by 1,2,3,4,5,6,7,8,9 ), with all_nics as ( select * from nic_create_op_logs UNION select * from nic_collect_logs ), select *, true_earliest as window_start, lead(true_earliest) over ( partition by nic_ip order by true_earliest asc ) as window_end from all_nics; And now we have NICs and the IPs associated with them and the window of time when that IP was associated with that NIC.\nOur next step is to join this on VM data. That\u0026rsquo;s fairly easy.\nFor our Azure VMs, we did a similar exercise of joining data from Collect script and Operational logs. We\u0026rsquo;ll call this view AZURE_VMS_V. We\u0026rsquo;ll call our Azure NICs view AZURE_NICS_V.\nselect * from AZURE_NICS_V a join AZURE_VMS_V b on lower(a.id) = lower(b.properties['networkProfile']['networkInterfaces'][0]['id]) A few notes - I used lower since there were some instances where the ID had varying cases and other instances where it didn\u0026rsquo;t. I\u0026rsquo;m attributing this to inconsistences with the APIs between collection scripts vs operational logs. You may also note that I used 0 instead of lateral flatten for accessing the network interfaces of the VMs. In our environment, we do not have VMs where there are multiple NICs. If you do, you can use lateral flatten again.\nThe final step is to join our flow logs on our NICs. In this way we\u0026rsquo;ll have joined Flow Log \u0026lt;\u0026gt; NIC \u0026lt;\u0026gt; VM. Fortunately, most of the hardwork is done.\nselect * from AZURE_FLOW_LOGS_V left outer join AZURE_NICS_V on src_addr = nic_ip and event_time \u0026gt;= window_start and (event_time \u0026lt;= window_end or window_end is NULL) left outer join AZURE_VMS_V on lower(AZURE_NICS_V.id) = lower(AZURE_VMS_V.properties['networkProfile']['networkInterfaces'][0]['id]) For joining the flow logs on the NIC, we want to ensure that the Flow Log event time occurred after the window start for the NIC and before the end time of the NIC. If the NIC still exists, the window_end would be NULL.\nIf you seek higher fidelity, you can also look at including tenant ID and subscription ID into your joins.\nThe obvious question is \u0026ldquo;how accurate is this?\u0026rdquo;\nLet\u0026rsquo;s check. I\u0026rsquo;ll call our above logic AZURE_FLOW_LOGS_JOIN_VMS_V. We\u0026rsquo;ll look for null VM IDs (where we couldn\u0026rsquo;t join on a VM) and the flow was recorded in the past day. (flow_recorded_at is a column we add during ingestion that records the time the flow was ingested into Snowflake.)\nselect count(*) from AZURE_FLOW_LOGS_JOIN_VMS_V where vm_id is NULL and flow_recorded_at \u0026gt;= dateadd(hour, -1, current_timestamp()) and something similar for not null showed me that 99.75% of flow logs could be matched to their VM.\nConclusion This was a lot of work for something that AWS offers natively. I hope that as Azure matures their product that they\u0026rsquo;ll also offer similar levels of visibility.\nYou may be wondering why I used IPs instead of MAC addresses. When inspecting our logs, a vast number of NICs has IPs but no MAC addresses. I do not have a clear reason from Microsoft why that is at the time of this publication.\nI hope this work helps those working in security and Azure clouds. If you have other ideas or ways to improve the success rate, please let me know!\n",
    "ref": "/blog/azureflowloganalysis/"
  },{
    "title": "About",
    "date": "",
    "description": "Daniel's thoughts on infosec",
    "body": "I\u0026rsquo;m a security engineer at Snowflake who also enjoys computers, coffee, cats, Muay Thai, and BJJ\n",
    "ref": "/about/"
  },{
    "title": "Regarding SMS 2FA",
    "date": "",
    "description": "Responding to Tavis Ormandy's comments on SMS 2FA",
    "body": "I think an important question that Tavis either explicitly or accidentally omitted is \u0026ldquo;for whom\u0026rdquo;. I am not sure why he did not include this as it\u0026rsquo;s a critical component to his argument. If Tavis is stating that \u0026ldquo;SMS 2FA is ineffective for an enterprise\u0026rdquo;, then I would agree. The threat model that he is operating from is that an organization is being explicitly targeted by a motivated (though not necessarily extremely capable) attacker, who only needs minimal access to cause great harm. However, if Tavis is instead simply stating \u0026ldquo;SMS 2FA is ineffective\u0026rdquo; with no caveats, I would disagree.\nWhen considering SMS 2FA, one needs to look at their threat model and personal risk. To argue this point, I will attempt to address his points from the perspective of a technologically immature individual looking to secure their bank account. In this context, one\u0026rsquo;s threat model changes from \u0026ldquo;I need to protect all the accounts\u0026rdquo; to \u0026ldquo;I simply need to make sure my account is more secure than someone else\u0026rsquo;s\u0026rdquo;. From this perspective, SMS 2FA provides significantly more protection from credential stuffing than a username/password combination. In addition, the argument of \u0026ldquo;an attacker can simply move to a different service\u0026rdquo; no longer holds as not all accounts for this user are of equal importance. Access to their neopets account is significantly less valuable than their bank account.\nAnother one of Tavis' arguments is \u0026ldquo;Instead, why not simply randomly generate a good password for them, and instruct them to write it down or save it in their web browser? If they lose it, they can use your existing password reset procedure.\u0026rdquo; I think this argument ignores the reality of today\u0026rsquo;s world in that, if a commercial service forced that kind of policy, it would not be adopted by users. Anyone who has worked with a technologically immature user can attest to how common it is for users to forget or lose their password. While, again, I can see such a service working for an enterprise product, I do not see such an authentication scheme being acceptable for a B2C product.\nI\u0026rsquo;d also like to discuss his point of \u0026ldquo;We have a finite pool of good will with which we can advocate for the implementation of new security technologies. If we spend all that good will on irritating attackers, then by the time we’re ready to actually implement a solution, developers are not going to be interested.\u0026rdquo; As far as I can tell, Tavis is arguing that if one invests their time in implementing 2FA, then developers will not be interested in allowing or enforcing more secure options. Coming from the perspective of someone who has worked with numerous developers during my time with consulting, I do not feel that this is true. Security is top of mind for numerous companies. Account compromise not only has a cost to a user, but also has a cost the service provider. This can be in terms of refunds, time spent restoring access, or other direct resource cost. Additionally, I think Tavis is oversimplifying the argument. His statement of \u0026ldquo;all that good will\u0026rdquo; implies that implementing SMS 2FA will \u0026ldquo;use up\u0026rdquo; security\u0026rsquo;s ability to influence the security features a product will implement. He exhibits a false dichotomy logical fallacy where he represents the decision as either all or nothing.\nSecurity is ultimately a risk calculation. SMS 2FA doesn\u0026rsquo;t prevent malware and it doesn\u0026rsquo;t prevent phishing. However, risk is about using your resources to make the impact or likelihood of a failure event. SMS 2FA does just that by efficiently reducing the likelihood of credential stuffing attacks. Do I wish that all sites supported U2F for 2FA and do I encourage everyone to use a password manager to generate random passwords? Yes. Will I continue to recommend that enterprises not support SMS 2FA for SSO and other solutions? Yes. However, I recognize the reality that we live in that password-based authentication is a bandaid for the larger identity problem for the world wide web and B2C services. And I will continue to tell my friends and family that SMS 2FA is better than nothing. If you have counterarguments, please feel free to reach out via email or twitter, and I\u0026rsquo;d be happy to respond in an addendum to this post. Have a great weekend and remember to be respectful in your discourse.\n",
    "ref": "/blog/regardingsms2fa/"
  },{
    "title": "Adding to the Dialogue - On the Release of Offensive Security Tools (OST)",
    "date": "",
    "description": "After a lot of dialogue recently on the release of Offensive Security Tools, I thought I would add to the dialogue in a more long-form format.",
    "body": "Update 1 - I\u0026rsquo;m clarifying the definition of Advanced Persistent Threats (APTs) and Financially Motivated Actors (FMAs). I combined the two groups in the previous version. The content and focus of the discussion primarily centers on FMAs. APTs and FMAs can overlap in terms of TTPs, capabilities, personnel, countries, etc. What distinguishes them is motivation. FMAs, as their name implies, are financially motivated. APTs can have a number of motivations including financial, political, etc.\nTwitter is a complicated social networking platform. Then again, which platform isn\u0026rsquo;t? I\u0026rsquo;m fairly new to tweeting, but I\u0026rsquo;ve already found that it can be a tremendous resource when it comes to receiving up-to-date information on new techniques, upcoming talks, or nifty vulnerabilities. What I haven\u0026rsquo;t found it useful for is having discussions, especially those surrounding a controversial idea. This has manifested in my feed over the past month with the discussion around the release of Offensive Security Tools, primarily ignited by Andrew Thompson (@QW5kcmV3).\nhttps://twitter.com/ItsReallyNick/status/1171145995050205185/photo/1\nOffensive Security Tools Before you read anymore, please read Andrew\u0026rsquo;s blog post on the Unrestricted Release of Offensive Security Tools as I\u0026rsquo;ll be using verbiage defined in that article. (Based on some of the discussions on Twitter where people have straw manned Microsoft\u0026rsquo;s operating system as an Offensive Security Tool (OST), I have confidence that not many people have actually read the article.) Andrew\u0026rsquo;s primary argument is that the unrestricted release of OST is causing more harm than good to the world. He\u0026rsquo;s passionately championed this idea on Twitter, pointing to data such as that available from his employer (FireEye/Mandiant) about actual breaches. Reaction to his argument has ranged from agreement to vitriolic outrage. (I do concede that some of the negative feedback may be due to his tone, which has not always been the friendliest.) Opposition has accused him of gatekeeping, exaggerating the magnitude of the problem, or just being plain wrong. Others have argued that this is a solved problem and wonder why it\u0026rsquo;s even being discussed. Later in this article, I will attempt to address and refute some of those arguments.\nSafe Spaces The second article I\u0026rsquo;d like you to read is, on the surface, unrelated to the discussion at hand. It\u0026rsquo;s a recently published piece by James Hatch titled My semester with the snowflakes. In the article, James discusses some of the assumptions he made about the students of Yale University prior to his first semester at the institution and how these assumptions were summarily shattered. One of these assumptions regarded the term \u0026ldquo;safe space\u0026rdquo;. James had long regarded the term to mean a place to discuss ideas without having one\u0026rsquo;s feelings hurt. He learned the truth is quite the opposite. \u0026ldquo;What she [his fellow student meant by ‘safe space' was that she was happy to be in an environment where difficult subjects can be discussed openly, without the risk of disrespect or harsh judgement.\u0026rdquo; Throughout the rest of this post, I\u0026rsquo;d like to adopt the same definition.\nTwitter is Not a Safe Space At this point, I\u0026rsquo;m hoping you can see where I\u0026rsquo;m going with this section. The recent tone of the dialogue surrounding Andrew\u0026rsquo;s argument shows me that we are more likely moving further from a solution than towards one. Individuals on both sides of the argument have been quick to judge each other\u0026rsquo;s motives and credentials and have sometimes done so with a healthy dollop of disrespect. Twitter is not a \u0026ldquo;safe space\u0026rdquo;. Your most likely reaction to that sentence is \u0026ldquo;well, no shit\u0026rdquo;. Why, then, is so much of this discussion happening on Twitter? It clearly is not the place to discuss a topic that is clearly controversial. It is true that one can reach a global audience instantly; however, it encourages short, witty responses instead of a deep dialogue. Where then, do we turn? Conferences are another common vehicle for presenting ideas. Unfortunately, they too do not lend themselves to the idea of having a dialogue. Conferences are primarily unidirectional communication: a speaker lectures an audience. There may be time for questions, but its brevity does not encourage in depth dialogue. Additionally, conferences artificially restrict themselves to those with the resources (time, money, influence) to attend.\nAt this point in time, I am not aware of a currently existing solution for having such discussions. During my time in the Air Force, teams would sponsor \u0026ldquo;working groups\u0026rdquo; with attendees from a variety of squadrons with different perspectives to gather and discuss complicated and controversial ideas. Such a solution in the commercial space would require significant sponsorship and buy-in from employers who would lose valuable resources for a period of time as they worked on a problem affecting a community. But it\u0026rsquo;s an idea.\nGatekeeping Another term I want to define as I\u0026rsquo;ve seen it come up quite a bit is \u0026ldquo;gatekeeping\u0026rdquo;. I\u0026rsquo;ll go with the Urban Dictionary definition which is \u0026ldquo;when someone takes it upon themselves to decide who does or does not have access or rights to a community or identity.\u0026rdquo; I\u0026rsquo;ll address gatekeeping later in this article, but I wanted to clarify the definition I\u0026rsquo;ll be using.\nArguments Against the Restriction of OST Release At this point in time, I\u0026rsquo;ve seen a number of arguments against Andrew\u0026rsquo;s position. I\u0026rsquo;ll be addressing each of these in their own section.\n The problem of restricting OST is too difficult. We have already solved this problem. The problem is blown out of proportion. There are two components to this.  FMAs aren\u0026rsquo;t using public OSTs. If OST wasn\u0026rsquo;t released, FMAs would develop their own.   Restricting the release of OST will gatekeep the offensive security community.  Logical Fallacies In addressing Andrew\u0026rsquo;s arguments, I\u0026rsquo;ve seen quite a few logical fallacies. I\u0026rsquo;ll address some examples I\u0026rsquo;ve seen here, so that others can be aware. For those who have used these arguments, I would encourage you to review the list and think to yourself if you\u0026rsquo;re committing one of these fallacies when engaging in debates.\nStraw Man Fallacy Windows is used by attackers - therefore you\u0026rsquo;re proposing we restrict the release of Operating Systems. This is obviously ludicrous, therefore, the argument to restrict OST is invalid.\nHere, someone is misrepresenting Andrew\u0026rsquo;s argument by providing an easy to refute example. It is \u0026ldquo;superficially similar but ultimately not equal version of [Andrew\u0026rsquo;s] real stance\u0026rdquo;.\nBandwagon Fallacy The majority of the community thinks restricting OST is wrong. Therefore, your proposition is invalid.\nJust because the majority agrees on something, doesn\u0026rsquo;t mean it\u0026rsquo;s correct.\nThe False Dilemma Fallacy Either we restrict all tools that can be used for attackers (including Empire, BloodHound, and SysInternals) or we restrict none of them.\nAgain, this misrepresents Andrew\u0026rsquo;s argument. If you read his earlier article and his recent postings, there is a spectrum of a tool classes that could be considered for restriction. It\u0026rsquo;s not an all-or-nothing argument.\nAnecdotal Evidence Fallacy I haven\u0026rsquo;t seen attackers use publicly released OSTs; therefore, it\u0026rsquo;s not a problem.\nA personal anecdote does not provide a preponderance of evidence to refute an argument.\nTexas Sharpshooter Fallacy, APT XYZ, Government ABC, and FMA 123 do not use OST. Therefore, your argument that these tools are a problem is invalid.\nThis argument is cherry picking data and ignores the other adversaries that are using OST as part of their activities.\nPersonal Incredulity Fallacy I don\u0026rsquo;t understand the various aspects of OST release. It\u0026rsquo;s too complicated and can\u0026rsquo;t be correct.\nOne\u0026rsquo;s ability to understand an argument does not affect the validity of the claim.\n\u0026ldquo;No True Scotsman\u0026rdquo; Fallacy No real hacker would argue for the restriction of OST. Hackers break down systems - they don\u0026rsquo;t create them!\nNo true APT or FMA would use OSTs.\nThis is one of my favorite logical fallacies. It relies on universal generalizations to \u0026ldquo;inaccurately deflect counterexamples\u0026rdquo;.\nThe Problem of Restricting OST is too Difficult This argument supposes that Andrew is correct with regards to the problem of releasing OSTs in that attackers are using them, and it is negatively impacting the security community. They contend that setting up a system to control the release of OST is too difficult. \u0026ldquo;Pandora\u0026rsquo;s box has been opened.\u0026rdquo; Therefore, it is not worth pursuing solutions.\nWhile I do agree with these individuals that the problem is difficult, I disagree with their conclusion that it is not worth pursuing a solution. I argue that, in information security, our responsibility is to reduce the number of attacks and how costly those attacks are as much as possible. If the data shows that OST is being used on a high number of high-impact attacks, we thus have a responsibility to reduce that as much as possible.\n\u0026ldquo;Just because something is hard doesn\u0026rsquo;t mean it\u0026rsquo;s impossible.\u0026rdquo; - Lysa TerKeurst\nWe Have Already Solved the Problem I\u0026rsquo;ve seen this from a number of users replying to Andrew\u0026rsquo;s article. Their comments are something along the lines of \u0026ldquo;Imagine talking about the release of OST in 2019…\u0026rdquo; or \u0026ldquo;Are we really talking about this gain?\u0026rdquo;. I have two responses.\n I would consider this gatekeeping. You\u0026rsquo;re creating an old guard and saying \u0026ldquo;we have previously decided the answer. You, not a member of the old guard, have no right to question our previous decisions.\u0026rdquo; Instead of being excluding, be open. Explain your decisions and why those decisions were made. Invite people to the conversation. Things change. While your decisions may have been correct when they were made, we cannot conclude that every decision will remain true for eternity. We must continuously question our assumptions and pressure test our decisions to see if they continue to stand up. It may have been that economies have changed and more attackers are relying on OST than before, and thus this conversation is worth revisiting.  APTs and FMAs Aren\u0026rsquo;t Using OST The data speaks for itself. Very few organizations have access to the volume and quality of data that Andrew has. While I\u0026rsquo;m trying to avoid the \u0026ldquo;appeal to authority\u0026rdquo; fallacy, I do believe Andrew when he states APT33 is using Empire, Metasploit, and Mimikatz. I address the logical fallacy regarding \u0026ldquo;no true APT\u0026rdquo; earlier. I do not believe this argument holds weight, but I would appreciate a fresh perspective if you disagree.\nIf OST Wasn\u0026rsquo;t Released, FMAs Would Just Develop Their Own This is my favorite argument because I think it is the most valid. I\u0026rsquo;ll decompose it into the various sub-arguments. Let us hold that this argument is valid. From that, people who hold this position draw a number of conclusions.\n Since FMAs would just develop their own OSTs, I would rather they use publicly released ones so that I can develop signatures from tools I am aware of. Since FMAs would just develop their own OSTs, the harm I do in releasing a OST is minimal since the capability would exist anyways. (If you have another reason that I missed, please reach out and I\u0026rsquo;ll update the article.)  The first argument supposes that organizations as a whole will be able to improve their security. Don\u0026rsquo;t forget the anecdotal evidence fallacy. Just because your organization is equipped to quickly respond and detect new threats does not mean the majority (or even 25%) of organizations have those capabilities. I think one thing the security industry doesn’t yet universally understand is a VAST majority of companies can barely manage basic security compliance. I agree with GossiTheDog based on my years of working with a number of organizations as well as from anecdotes I\u0026rsquo;ve heard from peers in the industry. That does not mean I\u0026rsquo;m correct. I believe the correct approach would be for a survey of a large number of organizations across a variety of sizes and verticals to assess if they have the capability to respond to new tools and signatures as well as how quickly they deploy them. I foresee that very few will have this capability.\nThe second argument contends that these tools would exist anyways, so there is no harm in releasing them. The first argument is partially correct - FMAs would invest in developing OST if they were not publicly released. However, they would HAVE to invest in developing OST if these tools were not released. As Andrew states in his article, adversaries, just like blue teams, have finite resources. If they invest in developing these capabilities, it inherently means that they\u0026rsquo;re not investing in other areas. The relationship between information security and risk management is inextricable. Our goal, as security professionals, should be to make it as difficult as possible for adversaries to achieve their goals. We can do that by not only making our defenses better but by reducing their capabilities.\nRestricting the Release of OST Will Gatekeep the Offensive Security Community This group argues that releasing OST helps with inclusion for the offensive security community. They argue, from what I can tell, that restricting these tools creates artificial barriers where those with the tools arbitrarily decide who and who does not have access to these capabilities.\nWhat follows is probably my most controversial opinion. I agree with this argument, but I also do not believe that this is a bad thing. I believe that offensive security professionals do not currently exist. To quote Wikipedia, \u0026ldquo;Major milestones which may mark an occupation being identified as a profession include:\nan occupation becomes a full-time occupation the establishment of a training school the establishment of a university school the establishment of a local association the establishment of a national association of professional ethics the establishment of state licensing laws\u0026rdquo;\nWhile one could argue that some certifications (such as CISSP) can define an information security professional, offensive security does not currently meet these definitions. The bar to declare yourself an offensive security professional, start a company, and begin selling services is very low.\nWhen we look at some examples of professions, we may begin to notice a trend: medicine, accounting, law, architecture, etc. Mistakes are not tolerated in these professions. People could die or go to jail (or both). I believe that information security (to include offensive security) meets this same bar. Incorrect and misinformed judgements and decisions can result in disastrous effects. I am not proposing that \u0026ldquo;the haves\u0026rdquo; wall themselves off in an ivory castle from the \u0026ldquo;have nots\u0026rdquo;. I am saying that gatekeeping in and of itself is not bad especially when it is done to protect the quality of work, so consumers have confidence in the product and services they are procuring. An organization purchasing the services of an MSSP or Red Team should have confidence that the company and its employees have adequate experience and capabilities to provide the services they are describing. There also does not need to be just one gate. Just like in medicine there are a variety of paths, certifications, schools, and specialties, so too could a system exist in information security. Just as some medicines are over-the-counter and some are \u0026ldquo;gatekept\u0026rdquo; by prescribing physicians, so too could certain tools be restricted to those who have shown the technical and ethical capacity to responsible exercise them.\nIf you agree or disagree, I\u0026rsquo;d really appreciate thoughts and discussions on this point.\nYou Didn\u0026rsquo;t Address my Argument Please reach out and I\u0026rsquo;ll update my article accordingly.\nFinal Thoughts We can\u0026rsquo;t move towards a solution for a problem until we agree that there\u0026rsquo;s a problem. Andrew clearly has data that shows that tools such as PowerShell Empire, Responder, etc. are being used in real-world breaches and costing companies time and money. If you rush to conclude that that\u0026rsquo;s an acceptable cost, then I encourage you to reconsider - not that you\u0026rsquo;re wrong, but that you refuse to even have your beliefs challenge. We are engineers, scientists, operators, analysts, managers, leaders, and executives. But we are not zealots and no idea should beyond question.\nFinally, we are on the same side. Offensive security or defensive security - if you consider yourself a white hat, we have the same objective: making the world a more secure place. Please keep that in mind when discussing tough ideas with your peers. Mutural respect goes a long way.\n",
    "ref": "/blog/opensourceredteamtooling/"
  },{
    "title": "Getting Started with Praetorian’s ATT&CK™ Automation",
    "date": "",
    "description": "We've had a couple of people reach out about how to get started with our automation. This is part one of a multipart series where we'll cover how to get started with our automation. In this post, I show how to get the automation installed, a payload up and running, and executing a basic module.",
    "body": "Blog link: Getting Started with Praetorian\u0026rsquo;s ATT\u0026amp;CK Automation\n",
    "ref": "/blog/gettingstartedwithautomation/"
  },{
    "title": "Why Praetorian Benchmarks to MITRE ATT&CK™ and Why You Should Too",
    "date": "",
    "description": "I wrote a blog post on Praetorian's website explaining why we chose to benchmark detection and response to MITRE ATT&CK™.",
    "body": "Blog link: Why Praetorian Benchmarks to MITRE ATT\u0026amp;CK™ and Why You Should Too\n",
    "ref": "/blog/attackbenchmark/"
  },{
    "title": "Demonstrating the Future of Command and Control with Wikipedia",
    "date": "",
    "description": "This tool demonstrates what I believe will be the future of Command and Control (C2) for Red Teams and potentially Advanced Persistent Threats (APTs). With Domain Fronting slowly being killed by major CDNs and security teams getting better at looking for unusual sites (I still love that detection for new sites encrypted with LetsEncrypt certificates), Red Teams will look for alternate ways to hide their traffic. What better way than to utilize features of common sites that users are visiting anyways?",
    "body": "This work was inspired by my coworker\u0026rsquo;s (Josh Abraham) work to demonstrate alternative forms of Command and Control. Some of his POCs included demonstrations using Slack and ICMP for C2. While these techniques aren\u0026rsquo;t revolutionary, the simplicity of the POC and how hard it was to detect confirmed my suspicion that the future of C2 is going to be tunneling traffic via features of well-known applications.\nIn addition, there was a recent Twitter post from @randomuserid that got me thinking about what other sites besides Slack could be utilized. So, I browsed through the Alexa top sites and started seeing what features could be abused to facilitate C2 traffic. The first few were all linked in @randomuserid\u0026rsquo;s Google sheet, so I moved onto wikipedia.org. It didn\u0026rsquo;t take me long to stumble onto the Wikipedia API page.\nWhen determining what API to use, I had two goals: I wanted my traffic to be private (so no public pages) and I wanted to be able to send a not insignificant amount of data. I started with the options API as it seemed that setting options for the current user (perhaps steganography via a user profile picture?) would be a plausible solution. Browsing the list of user options, one immediately stood out: userjs-arbitraryKeyName. After a bit of experimentation, it proved trivial to set the value of this option. In addition, testing revealed that the maximum size was 65535 characters - more than enough for a useful C2 channel.\nAs an attacker, I would be hesitant to use this method as my primary C2 channel. A well-positioned defender could potentially notice the spike in traffic to Wikipedia. Instead, I would use this similar to the way that Red Teams utilize C2 over DNS - a backup channel in case the primary method is blocked.\nAs a defender, I would continue with standard methods for identifying unusual spikes in traffic. Play with the POC and see how much data has to be transferred to cause a spike in traffic to Wikipedia. If you\u0026rsquo;re doing HTTPS interception, it\u0026rsquo;s unlikely that standard users are using the Wikipedia API. All that being said, I believe this technique would be incredibly difficult to detect for your average Blue Team. I\u0026rsquo;m a firm believer in focusing security on the endpoint, and demonstrations like this continue to confirm that belief.\nProject link: https://github.com/dweezy-netsec/wikipedia-c2\n",
    "ref": "/blog/wikipediac2/"
  },{
    "title": "Open Source SaaS Reconnaissance Utilizing Subdomains",
    "date": "",
    "description": "Investigations into enumeration of an organization's SaaS tooling",
    "body": "On a recent Purple Team engagement, I was accessing the client’s Splunk cloud instance. Being my normal typo-filled self, I fat fingered the URL and went to clieent.splunkcloud.com instead of the correct client.splunkcloud.com. Instead of being redirected to the login portal, I received a DNS resolution error, fixed the typo, and moved on. A little while later, I was thinking about the typo again and wondered how this information leakage could be utilized by an attacker. To backup a little, a key part of an offensive campaign (and many say the most critical part) is recon. During this phase, the Red Team or malicious actor tries to obtain as much information about the target as possible. Key items of interest include organizational charts, employee lists, email formats, external address space, and technologies utilized by the organization. During this phase, the attacker wants to limit their interaction with the target as much as possible in order to avoid tipping off defenders. Most attackers avoid active scanning or interaction with the target during this phase.\nSo back to my story. I wanted to answer two questions: 1. Could this technique be applied to identify other organizations that are using Splunk Cloud? 2. What other SaaS applications could I enumerate in this way?\nTo answer the first question, I pulled a CSV of the Fortune 500 companies and ran a very rudimentary bash loop to curl sites based on the company names.\nwhile read p; do echo $p; curl $p.splunkcloud.com; done \u0026lt; ~/f500.txt \u0026gt; ~/f500_splunkcloud.txt\nSurprisingly, this returned 29 results. I then built a better wordlist for the first 150 companies and compared that with what was returned for the top 150 from the basic list. As an example, for “Capital One Financial”, my first list only contained “capitalonefinancial”. In the second list, I also included “capitalone”. This yieled 14 companies in the top 150 utilizing slunkcloud.com whereas the basic search had returned only 9 in the top 150. My basic search of the Fortune 500 yielded 29 companies using splunkcloud.com, though I’m sure that would return more results if I built a better wordlist.\nMy next goal was to see if this worked for other SaaS applications. In a few minutes of digging, I identified that Okta, Zoom, Atlassian, Slack, Box, and Zendesk also offer the same opportunities for open source recon (I’m intentionally avoiding the word “vulnerability” as I don’t believe this qualifies). A few of these sites were a bit more difficult to figure out. As an example, entering an invalid Okta url will still land you on a valid sign-in page. Fortunately, most organization upload their logo when making an Okta login page and we can grep for logoText and identify which of these pages are actually valid.\nwhile read p; do echo $p; curl -L $p.okta.com | grep logoText; done \u0026lt; ~/top150.txt \u0026gt; top150_okta.txt\nUtilizing my same top 150 list with some adjustments, I found that 31 of the top 150 Fortune 500 companies are using Okta. (Some false positives may be in there.)\nFor Slack, I simply had to look for the phrase “There’s been a glitch” which was returned on invalid subdomains. My list yielded quite a few false positives so I had to grep based on email addresses to ensure I had the right organization.\nwhile read p; do echo $p; curl -L $p.slack.com | tr -d \u0026lsquo;\\n\u0026rsquo; | grep -v \u0026ldquo;There\u0026rsquo;s been a glitch\u0026rdquo; ; done \u0026lt; ~/top150.txt \u0026gt; top150_slack.txt cat top150_slack.txt | grep -o \u0026lsquo;data-team-email-domains-formatted.{0,30}'\nI’d like to give a special shout-out to the folks at 1password.com. As far as I could tell, valid and invalid login pages presented the exact same content.\nSo what should you take away from this? As an attacker, build a list of SaaS applications to check prior to each engagement and add that to your playbook. As a defender, unless the vendor makes changes, I don’t see many options for preventing this type of recon. I’d be happy to receive emails if you have ideas. Make sure to monitor for logins to all your SaaS applications. Utilize a robust IAM solution. You could also consider setting up honey services. Say your a Microsoft Teams organization (some do exist, trust me), you could register for a basic Slack account and monitor for attempted logins. I haven’t done the research, but I’d bet that most failed logins would likely be a part of an advanced campaign as opposed to merely bots.\nIf you have experience in this area (either defending against this or using it on your Red Teams), I’d be happy to hear your stories!\nAll opinions in this article are my own.\nUpdate: I felt like this work needed a POC and I wanted to practice some basic Go, so I coded this up! I added a few more SaaS applications (SalesForce and Adobe Creative Cloud) and removed Zendesk as I felt there were too many false posities. Check it out https://github.com/daniel-infosec/subsaas.\n",
    "ref": "/blog/opensourcesubdomainrecon/"
  }]
